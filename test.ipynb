{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "import torch\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "\n",
    "def NLL_loss(mu: Variable, sigma: Variable, labels: Variable):\n",
    "    \"\"\"\n",
    "    Negative Log Likelihood loss function.\n",
    "    Compute using gaussian the log-likehood which needs to be maximized. \n",
    "    Ignore time steps where labels are missing.\n",
    "\n",
    "    Args:\n",
    "        mu: (Variable) dimension [batch_size] - estimated mean at time step t\n",
    "        sigma: (Variable) dimension [batch_size] - estimated standard deviation at time step t\n",
    "        labels: (Variable) dimension [batch_size] z_t\n",
    "    Returns:\n",
    "        loss: (Variable) average log-likelihood loss across the batch\n",
    "    \"\"\"\n",
    "    # TODO: commented out zero_index since we also want to overfit on the zero data points\n",
    "    # zero_index = (labels != 0)\n",
    "    # distribution = torch.distributions.normal.Normal(mu[zero_index], sigma[zero_index])\n",
    "    # likelihood = distribution.log_prob(labels[zero_index])\n",
    "    ###########################################################################################\n",
    "    def nll_one_timestep(mu_one, sigma_one, labels_one):\n",
    "        distribution = torch.distributions.normal.Normal(mu_one, sigma_one)\n",
    "        likelihood = distribution.log_prob(labels_one)\n",
    "        print(mu_one, labels_one)\n",
    "        print(-likelihood)\n",
    "        print(\"**************\")\n",
    "        return -torch.mean(likelihood)\n",
    "\n",
    "    if len(mu.shape) == 1:\n",
    "        # mu: (B,)\n",
    "        return nll_one_timestep(mu, sigma, labels)\n",
    "    elif len(mu.shape) == 2:\n",
    "        # mu: (B, T)\n",
    "        T = mu.shape[1]\n",
    "        return sum(nll_one_timestep(mu[:, t], sigma[:, t], labels[:, t]) for t in range(T))\n",
    "\n",
    "\n",
    "# def NLL_loss(mu: Variable, sigma: Variable, labels: Variable):\n",
    "#     distribution = torch.distributions.normal.Normal(mu, sigma)\n",
    "#     likelihood = distribution.log_prob(labels)\n",
    "#     print(-likelihood)\n",
    "#     print(\"**************\")\n",
    "#     return -torch.mean(likelihood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 1]) tensor([1, 4])\n",
      "tensor([0.9189, 5.4189])\n",
      "**************\n",
      "tensor([1, 1]) tensor([3, 1])\n",
      "tensor([2.9189, 0.9189])\n",
      "**************\n",
      "tensor([1, 1]) tensor([4, 7])\n",
      "tensor([ 5.4189, 18.9189])\n",
      "**************\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(17.2568)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu = torch.tensor([\n",
    "  [1, 1, 1],\n",
    "  [1, 1, 1]\n",
    "])\n",
    "\n",
    "sigma = torch.tensor([\n",
    "  [1,1,1],\n",
    "  [1,1,1]\n",
    "])\n",
    "\n",
    "labels = torch.tensor([\n",
    "  [1,3,4],\n",
    "  [4,1,7]\n",
    "])\n",
    "\n",
    "NLL_loss(mu, sigma, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8d4f39e0e8945dc85ebf8adbc1053c185ae86818447b4d946a2f79d15397e919"
  },
  "kernelspec": {
   "display_name": "Python 3.7.12 ('db')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}